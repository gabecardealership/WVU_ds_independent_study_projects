{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "In this notebook, we perform Topic Modeling using spaCy, incluing a variety of preprocessing steps to get us there. The **Data** for this project comes from the link: https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/.\n",
    "\n",
    "Note that only the Appliances Dataset, which contains 602,777 reviews for appliances. This was saved locally then downloaded into the notebook.\n",
    "\n",
    "Then, we perform an investigation of these results, with the goals of being able to make sense of/interpret the topics that were output. This was the task for the work after 2/28/24. I was interested in not only the topics themselves, but what they were describing, and this was done be examining the documents that had very high representations of a specific topic (indicating that they were at the center of the cluster?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is work done before 2/28/24..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T03:21:30.572289Z",
     "iopub.status.busy": "2024-05-16T03:21:30.571919Z",
     "iopub.status.idle": "2024-05-16T03:21:54.436110Z",
     "shell.execute_reply": "2024-05-16T03:21:54.434918Z",
     "shell.execute_reply.started": "2024-05-16T03:21:30.572260Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:24.313097Z",
     "iopub.status.busy": "2024-03-03T23:08:24.312763Z",
     "iopub.status.idle": "2024-03-03T23:08:30.130553Z",
     "shell.execute_reply": "2024-03-03T23:08:30.128819Z",
     "shell.execute_reply.started": "2024-03-03T23:08:24.313068Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load the English Tokenizer, tagger, etc...\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:30.133378Z",
     "iopub.status.busy": "2024-03-03T23:08:30.132872Z",
     "iopub.status.idle": "2024-03-03T23:08:30.143355Z",
     "shell.execute_reply": "2024-03-03T23:08:30.141679Z",
     "shell.execute_reply.started": "2024-03-03T23:08:30.133339Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read, View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:30.145096Z",
     "iopub.status.busy": "2024-03-03T23:08:30.144684Z",
     "iopub.status.idle": "2024-03-03T23:08:40.854614Z",
     "shell.execute_reply": "2024-03-03T23:08:40.853550Z",
     "shell.execute_reply.started": "2024-03-03T23:08:30.145054Z"
    }
   },
   "outputs": [],
   "source": [
    "#Read in the .json data\n",
    "appliances_data = pd.read_json('Appliances.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:40.856342Z",
     "iopub.status.busy": "2024-03-03T23:08:40.856017Z",
     "iopub.status.idle": "2024-03-03T23:08:40.881753Z",
     "shell.execute_reply": "2024-03-03T23:08:40.880528Z",
     "shell.execute_reply.started": "2024-03-03T23:08:40.856316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>11 27, 2013</td>\n",
       "      <td>A3NHUQ33CFH3VM</td>\n",
       "      <td>1118461304</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Greeny</td>\n",
       "      <td>Not one thing in this book seemed an obvious o...</td>\n",
       "      <td>Clear on what leads to innovation</td>\n",
       "      <td>1385510400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>11 1, 2013</td>\n",
       "      <td>A3SK6VNBQDNBJE</td>\n",
       "      <td>1118461304</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Leif C. Ulstrup</td>\n",
       "      <td>I have enjoyed Dr. Alan Gregerman's weekly blo...</td>\n",
       "      <td>Becoming more innovative by opening yourself t...</td>\n",
       "      <td>1383264000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>10 10, 2013</td>\n",
       "      <td>A3SOFHUR27FO3K</td>\n",
       "      <td>1118461304</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Harry Gilbert Miller III</td>\n",
       "      <td>Alan Gregerman believes that innovation comes ...</td>\n",
       "      <td>The World from Different Perspectives</td>\n",
       "      <td>1381363200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>10 9, 2013</td>\n",
       "      <td>A1HOG1PYCAE157</td>\n",
       "      <td>1118461304</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Rebecca Ripley</td>\n",
       "      <td>Alan Gregerman is a smart, funny, entertaining...</td>\n",
       "      <td>Strangers are Your New Best Friends</td>\n",
       "      <td>1381276800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>09 7, 2013</td>\n",
       "      <td>A26JGAM6GZMM4V</td>\n",
       "      <td>1118461304</td>\n",
       "      <td>{'Format:': ' Hardcover'}</td>\n",
       "      <td>Robert Morris</td>\n",
       "      <td>As I began to read this book, I was again remi...</td>\n",
       "      <td>How and why it is imperative to engage, learn ...</td>\n",
       "      <td>1378512000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5    2     False  11 27, 2013  A3NHUQ33CFH3VM  1118461304   \n",
       "1        5  NaN     False   11 1, 2013  A3SK6VNBQDNBJE  1118461304   \n",
       "2        5  NaN     False  10 10, 2013  A3SOFHUR27FO3K  1118461304   \n",
       "3        5  NaN     False   10 9, 2013  A1HOG1PYCAE157  1118461304   \n",
       "4        5   10     False   09 7, 2013  A26JGAM6GZMM4V  1118461304   \n",
       "\n",
       "                            style              reviewerName  \\\n",
       "0       {'Format:': ' Hardcover'}                    Greeny   \n",
       "1  {'Format:': ' Kindle Edition'}           Leif C. Ulstrup   \n",
       "2       {'Format:': ' Hardcover'}  Harry Gilbert Miller III   \n",
       "3       {'Format:': ' Hardcover'}            Rebecca Ripley   \n",
       "4       {'Format:': ' Hardcover'}             Robert Morris   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Not one thing in this book seemed an obvious o...   \n",
       "1  I have enjoyed Dr. Alan Gregerman's weekly blo...   \n",
       "2  Alan Gregerman believes that innovation comes ...   \n",
       "3  Alan Gregerman is a smart, funny, entertaining...   \n",
       "4  As I began to read this book, I was again remi...   \n",
       "\n",
       "                                             summary  unixReviewTime image  \n",
       "0                  Clear on what leads to innovation      1385510400   NaN  \n",
       "1  Becoming more innovative by opening yourself t...      1383264000   NaN  \n",
       "2              The World from Different Perspectives      1381363200   NaN  \n",
       "3                Strangers are Your New Best Friends      1381276800   NaN  \n",
       "4  How and why it is imperative to engage, learn ...      1378512000   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Head of df\n",
    "appliances_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a lot of columns, however the only one that we will one for this is reviewText. Lets read the first few..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:40.883938Z",
     "iopub.status.busy": "2024-03-03T23:08:40.883517Z",
     "iopub.status.idle": "2024-03-03T23:08:40.894566Z",
     "shell.execute_reply": "2024-03-03T23:08:40.893213Z",
     "shell.execute_reply.started": "2024-03-03T23:08:40.883901Z"
    }
   },
   "outputs": [],
   "source": [
    "appliances_data.head()['reviewText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is weird...It seems that these are about books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:40.896614Z",
     "iopub.status.busy": "2024-03-03T23:08:40.896172Z",
     "iopub.status.idle": "2024-03-03T23:08:40.907602Z",
     "shell.execute_reply": "2024-03-03T23:08:40.906478Z",
     "shell.execute_reply.started": "2024-03-03T23:08:40.896578Z"
    }
   },
   "outputs": [],
   "source": [
    "#So they arent ALL about books, but some of them are. Lets leave them in for now, but we should note it for the analysis\n",
    "appliances_data['reviewText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few problems with the reviews are noted and handled here...\n",
    "\n",
    "- There are missing values in the list of reviews\n",
    "- '\\n' characters are in the reviews\n",
    "- '\\</a>' tags are in the reviews\n",
    "- Some other html are in the reviews...'\\<a data-hook=\"product-link-linked\" class=\"a-link-normal\" href=\"/The-Necessity-of-Strangers-The-Intriguing-Truth-About-Insight-Innovation-and-Success/dp/1118461304/ref=cm_cr_arp_d_rvw_txt?ie=UTF8\">' for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:40.912131Z",
     "iopub.status.busy": "2024-03-03T23:08:40.911780Z",
     "iopub.status.idle": "2024-03-03T23:08:41.374590Z",
     "shell.execute_reply": "2024-03-03T23:08:41.373345Z",
     "shell.execute_reply.started": "2024-03-03T23:08:40.912089Z"
    }
   },
   "outputs": [],
   "source": [
    "#See number of missing reviews\n",
    "print(appliances_data['reviewText'].isna().sum())\n",
    "\n",
    "#Filter out these reviews \n",
    "appliances_data = appliances_data.dropna(subset=['reviewText'])\n",
    "\n",
    "#Make sure this worked\n",
    "print(appliances_data['reviewText'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:41.376345Z",
     "iopub.status.busy": "2024-03-03T23:08:41.375966Z",
     "iopub.status.idle": "2024-03-03T23:08:42.149627Z",
     "shell.execute_reply": "2024-03-03T23:08:42.148542Z",
     "shell.execute_reply.started": "2024-03-03T23:08:41.376314Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert the reviews to a list, it will be easier to handle the \\n and \\' here\n",
    "reviews_list = appliances_data['reviewText'].tolist()\n",
    "\n",
    "#I only want the first 10,000 of these reviews, as 600k was taking a long time to \n",
    "#process through\n",
    "random.shuffle(reviews_list)\n",
    "reviews_list = reviews_list[0:9999]\n",
    "\n",
    "\n",
    "\n",
    "#Create empty list to add the cleaned reviews to\n",
    "cleaned_reviews = []\n",
    "\n",
    "#Iterate thru this list and remove these problems from the strings in the list. \n",
    "reviews_list = [review.replace('\\n','').replace('</a>', '') for review in reviews_list]\n",
    "\n",
    "for review in reviews_list:\n",
    "    review = review.replace('\\n','')\n",
    "    review = re.sub(r'<\\s*[^<>]+\\s*>', '', review)\n",
    "    cleaned_reviews.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn Reviews Into spaCy Documents and Tokens\n",
    "\n",
    "\n",
    "### Function to do this: tokenize_reviews()\n",
    "\n",
    "**Input**:  \n",
    "- *review*: A review\n",
    "\n",
    "**Output**:\n",
    "- *tokens*: A list of tokens from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:42.151345Z",
     "iopub.status.busy": "2024-03-03T23:08:42.150998Z",
     "iopub.status.idle": "2024-03-03T23:08:42.157648Z",
     "shell.execute_reply": "2024-03-03T23:08:42.156402Z",
     "shell.execute_reply.started": "2024-03-03T23:08:42.151316Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_reviews(review):\n",
    "    \n",
    "    #Tokenize and preprocess review\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    #Lemmatize and remove stop words from the doc\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:08:42.159842Z",
     "iopub.status.busy": "2024-03-03T23:08:42.159288Z",
     "iopub.status.idle": "2024-03-03T23:11:06.314247Z",
     "shell.execute_reply": "2024-03-03T23:11:06.313144Z",
     "shell.execute_reply.started": "2024-03-03T23:08:42.159813Z"
    }
   },
   "outputs": [],
   "source": [
    "#Init. empty list that will be filled when preprocessing each doc\n",
    "processed_docs = []\n",
    "\n",
    "#Counter for our progress:\n",
    "i=0\n",
    "\n",
    "#Preprocess each doc\n",
    "for review in cleaned_reviews:\n",
    "    processed_docs.append(tokenize_reviews(review))\n",
    "    i+=1\n",
    "    \n",
    "    #Print the progress in a way that it only stays on 1 line\n",
    "    print(f'Preprocessing Iteration {i}/10,000', end='\\r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Topic Modeling Model Using LDA\n",
    "\n",
    "LDA (Latent Dirichlet Allocation) is a widely-used statistical model for topic modeling, where abstract topics in a collection of documents are discovered. The goal of **Topic Modeling** is to automatically identify the underlying topics that are found in a large corpus of text data.  \n",
    "\n",
    "Each document is represented as a mixture of topics, where each topic is characterized by a distribution over words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary\n",
    "\n",
    "This dictionary maps the word IDs to words from our processed_docs. It has the following attributes and methods...\n",
    "\n",
    "- token2id: A dictionary that maps tokens (words) to their unique integer IDs.\n",
    "- id2token: A dictionary that maps integer IDs to their corresponding tokens.\n",
    "- dfs: A dictionary that stores the document frequencies of tokens in the corpus.\n",
    "- num_docs: The total number of documents in the corpus.\n",
    "- num_pos: The total number of tokens in the corpus.\n",
    "- num_nnz: The total number of non-zero entries in the dfs dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:06.315810Z",
     "iopub.status.busy": "2024-03-03T23:11:06.315517Z",
     "iopub.status.idle": "2024-03-03T23:11:06.642123Z",
     "shell.execute_reply": "2024-03-03T23:11:06.641319Z",
     "shell.execute_reply.started": "2024-03-03T23:11:06.315784Z"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:06.643999Z",
     "iopub.status.busy": "2024-03-03T23:11:06.643138Z",
     "iopub.status.idle": "2024-03-03T23:11:06.649392Z",
     "shell.execute_reply": "2024-03-03T23:11:06.648277Z",
     "shell.execute_reply.started": "2024-03-03T23:11:06.643968Z"
    }
   },
   "outputs": [],
   "source": [
    "#View the contents of this dictionary\n",
    "print(dictionary.num_docs)\n",
    "print(dictionary.num_pos)\n",
    "print(dictionary.num_nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Create corpus from the dictionary\n",
    " \n",
    " It converts the list of tokens into a bag of words format. It creates a compact and efficient representation of the text data that can be used as input for the models. It captures the frequency of each word, but does seem to be a rather elementary task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:06.652240Z",
     "iopub.status.busy": "2024-03-03T23:11:06.650974Z",
     "iopub.status.idle": "2024-03-03T23:11:06.835634Z",
     "shell.execute_reply": "2024-03-03T23:11:06.834646Z",
     "shell.execute_reply.started": "2024-03-03T23:11:06.652208Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in processed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the LDA Model\n",
    "\n",
    "#### Some Parameters: \n",
    "\n",
    "- corpus: The bag-of-words corpus \n",
    "- id2word: The mapping of word IDs to words, typically created using Gensim's Dictionary class.\n",
    "- num_topics: The number of topics to extract from the text data. This is the number of clusters.\n",
    "- passes: The number of passes (iterations) over the corpus during training. More passes can lead to better results but also increase computation time.\n",
    "\n",
    "Others...\n",
    "\n",
    "- alpha: The hyperparameter controlling the sparsity of the document-topic distributions. By default, this is set to 'symmetric', which means all documents have the same prior.\n",
    "- eta: The hyperparameter controlling the sparsity of the topic-word distributions. By default, this is set to 'symmetric', which means all topics have the same prior.\n",
    "- chunksize: The number of documents to load into memory at a time. This can affect memory usage and training speed.\n",
    "- minimum_probability: The minimum probability value for a topic or word in the topic-word distribution to be considered in the output. Low values can help filter out noise.\n",
    "- iterations: The maximum number of iterations for each document. This can affect the quality of the inferred topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:06.838191Z",
     "iopub.status.busy": "2024-03-03T23:11:06.837293Z",
     "iopub.status.idle": "2024-03-03T23:11:47.406302Z",
     "shell.execute_reply": "2024-03-03T23:11:47.404925Z",
     "shell.execute_reply.started": "2024-03-03T23:11:06.838150Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, passes=10, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:47.408525Z",
     "iopub.status.busy": "2024-03-03T23:11:47.408141Z",
     "iopub.status.idle": "2024-03-03T23:11:47.418719Z",
     "shell.execute_reply": "2024-03-03T23:11:47.417248Z",
     "shell.execute_reply.started": "2024-03-03T23:11:47.408492Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_id, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {topic_id}: {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:47.420853Z",
     "iopub.status.busy": "2024-03-03T23:11:47.420490Z",
     "iopub.status.idle": "2024-03-03T23:11:53.469232Z",
     "shell.execute_reply": "2024-03-03T23:11:53.467876Z",
     "shell.execute_reply.started": "2024-03-03T23:11:47.420823Z"
    }
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is work done AFTER 2/28...\n",
    "\n",
    "In my 2/28 capstone class, we discussed a few ways to take this analysis to another level. Below is a summary of that discussion...\n",
    "\n",
    "- \"Relate the topics back to the documents\". A document is a distribution over topics. We can output the representations/distributions of topics (clusters) on each document. Doing this, we can gain some insight about these topics. What are the documents that have the highest proportion of topic $j$ saying about topic $j$?\n",
    "- Look into the PCA that was needed to create the above visual. What were the inputs used to generate these PCs?\n",
    "- **Understand that the key and goal in unsupervised learning is *DISCOVERY*. I have a good model now, however I now need to use it to discover some things...**\n",
    "document is typically represented as a distribution over topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is with the PCA?\n",
    "\n",
    "The PCA takes the input (I believe) of topic-term probabilites...This comes from the documentation:  https://pyldavis.readthedocs.io/en/latest/modules/API.html , although this does not have the documentaion for the gensim.prepare method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relating the Topics Back to the Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T00:52:05.651759Z",
     "iopub.status.busy": "2024-02-29T00:52:05.651367Z",
     "iopub.status.idle": "2024-02-29T00:52:05.704212Z",
     "shell.execute_reply": "2024-02-29T00:52:05.701943Z",
     "shell.execute_reply.started": "2024-02-29T00:52:05.651730Z"
    }
   },
   "source": [
    "### First step, for each document, $d$, get the distribution of each topic on $d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:53.472534Z",
     "iopub.status.busy": "2024-03-03T23:11:53.471178Z",
     "iopub.status.idle": "2024-03-03T23:11:56.701530Z",
     "shell.execute_reply": "2024-03-03T23:11:56.700138Z",
     "shell.execute_reply.started": "2024-03-03T23:11:53.472477Z"
    }
   },
   "outputs": [],
   "source": [
    "#Init. an empty list that we will fill with these distributions\n",
    "topic_distributions = []\n",
    "\n",
    "#Iterate thru the corpus, add these dists for each document.\n",
    "for document in corpus: \n",
    "    \n",
    "    #Add the topic ditribution to the list\n",
    "    topic_distributions.append(lda_model.get_document_topics(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:56.703179Z",
     "iopub.status.busy": "2024-03-03T23:11:56.702817Z",
     "iopub.status.idle": "2024-03-03T23:11:56.710989Z",
     "shell.execute_reply": "2024-03-03T23:11:56.709647Z",
     "shell.execute_reply.started": "2024-03-03T23:11:56.703150Z"
    }
   },
   "outputs": [],
   "source": [
    "#Look at this data structure's length\n",
    "len(topic_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:56.713109Z",
     "iopub.status.busy": "2024-03-03T23:11:56.712743Z",
     "iopub.status.idle": "2024-03-03T23:11:56.726745Z",
     "shell.execute_reply": "2024-03-03T23:11:56.725388Z",
     "shell.execute_reply.started": "2024-03-03T23:11:56.713079Z"
    }
   },
   "outputs": [],
   "source": [
    "#Look at first few values\n",
    "topic_distributions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that topic 7 has a pretty high representation in document 4. Lets loop thru all of these and create a new data structure that JUST has topics with a high concentration of the distribution of a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the docs that contain a very high proportion of a certain topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:56.729174Z",
     "iopub.status.busy": "2024-03-03T23:11:56.728660Z",
     "iopub.status.idle": "2024-03-03T23:11:57.132345Z",
     "shell.execute_reply": "2024-03-03T23:11:57.130922Z",
     "shell.execute_reply.started": "2024-03-03T23:11:56.729132Z"
    }
   },
   "outputs": [],
   "source": [
    "#Init. empty df that will be filled. We do a df for easier retrieval of info\n",
    "#Columns...\n",
    "    #Index Number: The document number that the document with a high concentration of a given topic is.\n",
    "    #High_Conc_Topic: The topic that is very highly represented in the document\n",
    "    #Proportion: The proportion that the topic is in the given document\n",
    "high_dist_amounts_df = pd.DataFrame(columns=['Index Number', 'High_Conc_Topic', 'Proportion'])\n",
    "\n",
    "#Init a counter that we reference when adding the high conc. topic distributions.\n",
    "doc_number = 0\n",
    "\n",
    "#Traverse thru the topic distributions\n",
    "for topic_dist in topic_distributions:\n",
    "    \n",
    "    #Traverse thru the tuples in each topic dist\n",
    "    for tup in topic_dist:\n",
    "        \n",
    "        #If the proportion is > than .90 we will consider it to be a high concentration\n",
    "        if tup[1] >= .90:\n",
    "            \n",
    "            #Append the tuple that gives us the topic and the associated proportion. I also want to add the document number, the index, to this so we will use a dict.\n",
    "            high_dist_amounts_df.loc[len(high_dist_amounts_df)] = [doc_number, tup[0], tup[1]]\n",
    "            \n",
    "    #Increment the counter\n",
    "    doc_number+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:57.134992Z",
     "iopub.status.busy": "2024-03-03T23:11:57.134163Z",
     "iopub.status.idle": "2024-03-03T23:11:57.156585Z",
     "shell.execute_reply": "2024-03-03T23:11:57.155279Z",
     "shell.execute_reply.started": "2024-03-03T23:11:57.134958Z"
    }
   },
   "outputs": [],
   "source": [
    "high_dist_amounts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Important note: The Topic numbers in this df are between 0-9 and correspond to the LDA output, but NOT the graph of the clusters using PCA. To translate between the df values and the graph, the graph's cluster numbers are 1 higher than the topic numbers in the df. So, 1 in the graph is topic 0 in the df, 2 in the graph is 1 in the df and etc...***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform some basic analysis on this df..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:57.159441Z",
     "iopub.status.busy": "2024-03-03T23:11:57.158989Z",
     "iopub.status.idle": "2024-03-03T23:11:57.177436Z",
     "shell.execute_reply": "2024-03-03T23:11:57.175903Z",
     "shell.execute_reply.started": "2024-03-03T23:11:57.159397Z"
    }
   },
   "outputs": [],
   "source": [
    "#Table of topic values\n",
    "high_dist_amounts_df['High_Conc_Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:57.179775Z",
     "iopub.status.busy": "2024-03-03T23:11:57.179352Z",
     "iopub.status.idle": "2024-03-03T23:11:57.194524Z",
     "shell.execute_reply": "2024-03-03T23:11:57.193242Z",
     "shell.execute_reply.started": "2024-03-03T23:11:57.179744Z"
    }
   },
   "outputs": [],
   "source": [
    "#Average proportion per topic\n",
    "high_dist_amounts_df.groupby('High_Conc_Topic')['Proportion'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is interesting. Topics 3 and 4 are, on average, EXTREMELY well represented in the documents where they have a distribution value of over .9.\n",
    "\n",
    "#### Now, for each of the 10 topics, I would like to examine the documents with these high concentrations of one topic. I will use a function to do this...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Examine the Documents with a high concentration of one Topic (From the data structures we have created above)\n",
    "\n",
    "**Inputs**:\n",
    "- *high_concentration_df*: The dataframe that contains the Indices, Topic, and Proportion of the corresponding document that is represented by the topic.\n",
    "- *processed_docs*: A list of the processed docs\n",
    "- *topic_number*: The number of topics that we want to examine\n",
    "\n",
    "**Output**:\n",
    "- *corresponding_processed_docs*: The processed documents at the indices of documents with a high concentration of the topic topic_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:11:57.196659Z",
     "iopub.status.busy": "2024-03-03T23:11:57.196299Z",
     "iopub.status.idle": "2024-03-03T23:11:57.204362Z",
     "shell.execute_reply": "2024-03-03T23:11:57.203185Z",
     "shell.execute_reply.started": "2024-03-03T23:11:57.196622Z"
    }
   },
   "outputs": [],
   "source": [
    "def examine_high_conc_docs(high_concentration_df, processed_docs, topic_number):\n",
    "    \n",
    "    #Get the indices in the df that are in the same row as all of the topic_number topic entries in the topic column.\n",
    "    indices_of_topic = high_concentration_df[high_concentration_df['High_Conc_Topic'] == topic_number]['Index Number'].to_list()\n",
    "    \n",
    "    #Init. list that will be filled with the processed documents at the indices in the indices_of_topic list\n",
    "    corresponding_processed_docs = []\n",
    "    \n",
    "    #For each of these indices, get the document from processed_docs at the same index and add it to my list that will be returned\n",
    "    for index in indices_of_topic:\n",
    "        corresponding_processed_docs.append(processed_docs[int(index)])\n",
    "    \n",
    "    return corresponding_processed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T18:11:44.140420Z",
     "iopub.status.busy": "2024-02-29T18:11:44.139506Z",
     "iopub.status.idle": "2024-02-29T18:11:44.179069Z",
     "shell.execute_reply": "2024-02-29T18:11:44.177845Z",
     "shell.execute_reply.started": "2024-02-29T18:11:44.140378Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# One-by-One, Examine the Documents for each of the 10 Topics\n",
    "\n",
    "One of the easiest ways to do this is through a WordCloud, so along with printing the lists, we will also display the WordCloud for each of the topics (remember, just the docs with the high distributions for that given topic)\n",
    "\n",
    "## Topic 0: \n",
    "\n",
    "### TOPIC 0 SUMMARY: \n",
    "\n",
    "**SEEMS TO BE DESCRIBING ITEMS THAT WORK WELL, THROUGH WORD LIKE \"WORK\", \"EASY\", \"EASY INSTALL\", ETC... IT IS INTERESTING THAT THESE SEEM TO ALSO BE ACCOMPANIED BY A YOUTUBE VIDEO, WHICH MAY FURTHER ENHANCE THE EASE OF USE AND SETTING UP THESE PRODUCTS. THERE SEEMS TO BE DRYERS, REFRIGERATORS, ETC. MENTIONED, BUT THESE ALL SEEM TO HAVE VERY EASY INSTALLATIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:15:25.298475Z",
     "iopub.status.busy": "2024-03-03T23:15:25.298008Z",
     "iopub.status.idle": "2024-03-03T23:15:25.309012Z",
     "shell.execute_reply": "2024-03-03T23:15:25.307624Z",
     "shell.execute_reply.started": "2024-03-03T23:15:25.298442Z"
    }
   },
   "outputs": [],
   "source": [
    "topic0_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 0)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic0_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:19:34.058429Z",
     "iopub.status.busy": "2024-03-03T23:19:34.057461Z",
     "iopub.status.idle": "2024-03-03T23:19:35.811289Z",
     "shell.execute_reply": "2024-03-03T23:19:35.809518Z",
     "shell.execute_reply.started": "2024-03-03T23:19:34.058385Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate wordcloud by adding these tokens to one string. Need this for the Wordcloud\n",
    "\n",
    "#Empty string that will be filled with all of the tokens\n",
    "topic0_tokens = \"\"\n",
    "\n",
    "for doc in topic0_high_conc_docs:\n",
    "    topic0_tokens+= \" \".join(doc) + \" \"\n",
    "\n",
    "#Create wordcloud\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(topic0_tokens)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 1: \n",
    "\n",
    "### TOPIC 1 SUMMARY: \n",
    "\n",
    "**SEEMS TO BE DESCRIBING ITEMS THAT DO NOT WORK WELL, AS WE SEE WORDS LIKE \"FIX\" AND \"PROBLEM\". IT IS INTERESTING THAT THERE ARE FAR LESS DOCUMENTS HERE, POSSIBLY INDICATING THAT THERE WERE NOT THAT MANY REVIEWS WITH NEGATIVE SENTIMENTS, OR THIS TOPIC DOES NOT SEEM TO BE VERY SPECIFIC.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:22:46.909611Z",
     "iopub.status.busy": "2024-03-03T23:22:46.909058Z",
     "iopub.status.idle": "2024-03-03T23:22:46.918544Z",
     "shell.execute_reply": "2024-03-03T23:22:46.916734Z",
     "shell.execute_reply.started": "2024-03-03T23:22:46.909573Z"
    }
   },
   "outputs": [],
   "source": [
    "topic1_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 1)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic1_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:23:23.692450Z",
     "iopub.status.busy": "2024-03-03T23:23:23.692022Z",
     "iopub.status.idle": "2024-03-03T23:23:25.144844Z",
     "shell.execute_reply": "2024-03-03T23:23:25.143543Z",
     "shell.execute_reply.started": "2024-03-03T23:23:23.692419Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate wordcloud by adding these tokens to one string. Need this for the Wordcloud\n",
    "\n",
    "#Empty string that will be filled with all of the tokens\n",
    "topic1_tokens = \"\"\n",
    "\n",
    "for doc in topic1_high_conc_docs:\n",
    "    topic1_tokens+= \" \".join(doc) + \" \"\n",
    "\n",
    "#Create wordcloud\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(topic1_tokens)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 2: \n",
    "\n",
    "### TOPIC 2 SUMMARY: \n",
    "\n",
    "**UNLIKE THE TWO PRIOR TOPICS, TOPIC 2 SEEMS TO PRETTY CLEARLY INVOLVE REVIEWS OF A REFRIDGERATOR/WATER FILTER. IT IS VERY INTERESTING HOW SO FAR, THESE TOPICS HAVE BOTH INCLUDED DIFFERENT SENTIMENTS OF REVIEWS, AND ALSO DIFFERENT PRODUCT REVIEWS ALL TOGETHER. THERE ARE QUITE A FEW REVIEWS OF THESE FRIDGES/FILTERS, WHICH COULD BE A TESTIMENT TO THE AMOUNT OF THEIR REVIEWS THAT ARE IN THE CORPUS.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:26:02.698334Z",
     "iopub.status.busy": "2024-03-03T23:26:02.697835Z",
     "iopub.status.idle": "2024-03-03T23:26:02.708818Z",
     "shell.execute_reply": "2024-03-03T23:26:02.707138Z",
     "shell.execute_reply.started": "2024-03-03T23:26:02.698301Z"
    }
   },
   "outputs": [],
   "source": [
    "topic2_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 2)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic2_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:26:23.134160Z",
     "iopub.status.busy": "2024-03-03T23:26:23.133693Z",
     "iopub.status.idle": "2024-03-03T23:26:24.930190Z",
     "shell.execute_reply": "2024-03-03T23:26:24.929023Z",
     "shell.execute_reply.started": "2024-03-03T23:26:23.134122Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate wordcloud by adding these tokens to one string. Need this for the Wordcloud\n",
    "\n",
    "#Empty string that will be filled with all of the tokens\n",
    "topic2_tokens = \"\"\n",
    "\n",
    "for doc in topic2_high_conc_docs:\n",
    "    topic2_tokens+= \" \".join(doc) + \" \"\n",
    "\n",
    "#Create wordcloud\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(topic2_tokens)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 3: \n",
    "\n",
    "### TOPIC 3 SUMMARY: \n",
    "\n",
    "**THESE REVIEWS FOR SOME REASON WERE ALL THE EXACT SAME, WHICH MAY HAVE BEEN DUE TO THE FACT THAT THERE WERE SOME REVIEWS THAT WERE COPIED(...?) IF I WERE TO DO THIS AGAIN, I CERTAINLY WOULD HAVE ACCOUNTED FOR THIS. IT SEEMS THAR A DRYER IS BEING REVIEWED IN THESE, HOWEVER I WILL SKIP ANY FURTHER ANALYSIS OF THIS TOPIC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:29:53.453117Z",
     "iopub.status.busy": "2024-03-03T23:29:53.452691Z",
     "iopub.status.idle": "2024-03-03T23:29:53.460838Z",
     "shell.execute_reply": "2024-03-03T23:29:53.459843Z",
     "shell.execute_reply.started": "2024-03-03T23:29:53.453084Z"
    }
   },
   "outputs": [],
   "source": [
    "topic3_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 3)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic3_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WELL... THIS IS WEIRD...WE SEE PRETTY MUCH THE SAME REVIEWS MANY TIMES. LETS STOP THE ANALYSIS FOR THIS TOPIC HERE..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 4: \n",
    "\n",
    "### TOPIC 4 SUMMARY: \n",
    "\n",
    "**THESE REVIEWS FOR SOME REASON WERE ALL THE EXACT SAME, WHICH MAY HAVE BEEN DUE TO THE FACT THAT THERE WERE SOME REVIEWS THAT WERE COPIED(...?) IF I WERE TO DO THIS AGAIN, I CERTAINLY WOULD HAVE ACCOUNTED FOR THIS. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:35:02.032079Z",
     "iopub.status.busy": "2024-03-03T23:35:02.031629Z",
     "iopub.status.idle": "2024-03-03T23:35:02.040990Z",
     "shell.execute_reply": "2024-03-03T23:35:02.039307Z",
     "shell.execute_reply.started": "2024-03-03T23:35:02.032048Z"
    }
   },
   "outputs": [],
   "source": [
    "topic4_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 4)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic4_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 5: \n",
    "\n",
    "### TOPIC 5 SUMMARY: \n",
    "\n",
    "**THERE ARE ONLY A VIEW DOCS HERE, HOWEVER THEY DO REVEAL SOME INTERESTING INFO. FOR ONE, I AM NOT MAKING A WORDCLOUD HERE BECAUSE IT WOULD BE DOMINATED BY THE TOKEN 'BLAH', WHICH IS PRETTY FUNNY. THESE REVIEWS SEEM TO BE QUITE GOOD, AND THERE IS ALSO A CUSTOMER SERVICE ASPECT TO THESE REVIEWS. I WONDER WHAT CUSTOMER SERVICE HAD TO DO WITH THIS PRODUCT? THIS IS A PRETTY INTERESTING FINDING, THOUGH...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:36:21.167278Z",
     "iopub.status.busy": "2024-03-03T23:36:21.166077Z",
     "iopub.status.idle": "2024-03-03T23:36:21.175206Z",
     "shell.execute_reply": "2024-03-03T23:36:21.174222Z",
     "shell.execute_reply.started": "2024-03-03T23:36:21.167212Z"
    }
   },
   "outputs": [],
   "source": [
    "topic5_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 5)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic5_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 6: \n",
    "\n",
    "### TOPIC 6 SUMMARY: \n",
    "\n",
    "**REVIEWERS HERE SEEMED TO RAVE ABOUT THE SLEEK LOOK OF PRODUCTS. NOW, WE HAVE ANOTHER SET OF POSITIVE REVIEWS, JUST LIKE TOPIC 0, BUT WE HAVE ONES WHERE REVIEWERS ARE IMPRESSED BY A PRODUCT'S APPEARANCE! PRETTY INTERESTING HOW THE TOPIC MODELING OUTPUT HAS DIFFERENT TOPICS FOR DIFFERENT ASPECTS OF PRODUCTS THAT WERE LIKED.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:40:26.687336Z",
     "iopub.status.busy": "2024-03-03T23:40:26.686818Z",
     "iopub.status.idle": "2024-03-03T23:40:26.696962Z",
     "shell.execute_reply": "2024-03-03T23:40:26.695365Z",
     "shell.execute_reply.started": "2024-03-03T23:40:26.687290Z"
    }
   },
   "outputs": [],
   "source": [
    "topic6_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 6)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic6_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:42:31.382125Z",
     "iopub.status.busy": "2024-03-03T23:42:31.381675Z",
     "iopub.status.idle": "2024-03-03T23:42:32.294476Z",
     "shell.execute_reply": "2024-03-03T23:42:32.293067Z",
     "shell.execute_reply.started": "2024-03-03T23:42:31.382086Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate wordcloud by adding these tokens to one string. Need this for the Wordcloud\n",
    "\n",
    "#Empty string that will be filled with all of the tokens\n",
    "topic6_tokens = \"\"\n",
    "\n",
    "for doc in topic6_high_conc_docs:\n",
    "    topic6_tokens+= \" \".join(doc) + \" \"\n",
    "\n",
    "#Create wordcloud\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(topic6_tokens)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 7: \n",
    "\n",
    "### TOPIC 7 SUMMARY: \n",
    "\n",
    "**IN THIS TOPIC, WE HAVE MORE POSITIVE REVIEWS ABOUT A WASHER AND A FRIDGE. THIS TIME, THOUGH, THE REVIEWERS ARE IMPRESSED BY THE ICE TRAY AND ICE-MAKING ABILITIES OF A FREEZER! THAT IS THE OVERWHELMING MAJORITY OF REVIEWS HERE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:44:53.800673Z",
     "iopub.status.busy": "2024-03-03T23:44:53.800203Z",
     "iopub.status.idle": "2024-03-03T23:44:53.810622Z",
     "shell.execute_reply": "2024-03-03T23:44:53.808832Z",
     "shell.execute_reply.started": "2024-03-03T23:44:53.800640Z"
    }
   },
   "outputs": [],
   "source": [
    "topic7_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 7)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic7_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:45:28.913753Z",
     "iopub.status.busy": "2024-03-03T23:45:28.913301Z",
     "iopub.status.idle": "2024-03-03T23:45:30.582127Z",
     "shell.execute_reply": "2024-03-03T23:45:30.580812Z",
     "shell.execute_reply.started": "2024-03-03T23:45:28.913719Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate wordcloud by adding these tokens to one string. Need this for the Wordcloud\n",
    "\n",
    "#Empty string that will be filled with all of the tokens\n",
    "topic7_tokens = \"\"\n",
    "\n",
    "for doc in topic7_high_conc_docs:\n",
    "    topic7_tokens+= \" \".join(doc) + \" \"\n",
    "\n",
    "#Create wordcloud\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(topic7_tokens)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 8: \n",
    "\n",
    "### TOPIC 8 SUMMARY: \n",
    "\n",
    "**NOT A LOT OF DOCS HERE, BUT WE SEE SOME NEGATIVE REVIEWS! THIS TOPIC IS ANOTHER THAT MAY BE FALLING VICTIM TO FEW DOCUMENTS BEING VERY LARGELY REPRESENTED BY THIS TOPIC. LIKE TOPIC 1, THERE ARE FEW DOCS HERE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:47:33.881393Z",
     "iopub.status.busy": "2024-03-03T23:47:33.880886Z",
     "iopub.status.idle": "2024-03-03T23:47:33.890208Z",
     "shell.execute_reply": "2024-03-03T23:47:33.888803Z",
     "shell.execute_reply.started": "2024-03-03T23:47:33.881356Z"
    }
   },
   "outputs": [],
   "source": [
    "topic8_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 8)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic8_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 9: \n",
    "\n",
    "### TOPIC 9 SUMMARY: \n",
    "\n",
    "**LASTLY, WE HAVE A HOSE THAT IS PRETTY AWFUL, WITH SEVERAL NEGATIVE REVIEWS!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the list of documents (just the cleaned tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:50:04.350219Z",
     "iopub.status.busy": "2024-03-03T23:50:04.349644Z",
     "iopub.status.idle": "2024-03-03T23:50:04.361339Z",
     "shell.execute_reply": "2024-03-03T23:50:04.359975Z",
     "shell.execute_reply.started": "2024-03-03T23:50:04.350177Z"
    }
   },
   "outputs": [],
   "source": [
    "topic9_high_conc_docs = examine_high_conc_docs(high_dist_amounts_df, processed_docs, 9)\n",
    "\n",
    "#Print these in a readable way.\n",
    "for doc in topic9_high_conc_docs:\n",
    "    print(' '. join(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY OF EXPLORATION INTO THE TOPIC MODELING RESULTS...\n",
    "\n",
    "Our goal of performing the Topic Modeling was *discovery*, where I wanted to discover different topics and themes that were present in a large corpus of Amazon appliance reviews. I was successfully able to create a topic modeling model and visualize its outputs, however the exploration did not stop there. I then wanted to dive deep into each of the 10 topics to discover similarities between them, and specifically *what* these topics were. This was done be examaning, for all topics, the documents that contained a very large proportion of one specific topic. These documents were thus very representative of a given topic. For all of these lists of documents & topics, they were examined and, when enough documents were present, visualized. I found interesting trends and themes in each of these topics, and they are listed throughout the 2nd half of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4480689,
     "sourceId": 7680107,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
